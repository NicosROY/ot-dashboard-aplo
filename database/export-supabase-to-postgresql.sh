#!/bin/bash

# Script d'export Supabase vers PostgreSQL local
# Usage: ./export-supabase-to-postgresql.sh

set -e

echo "ğŸ—„ï¸ Export Supabase vers PostgreSQL local"
echo "========================================"

# Variables
SUPABASE_URL="https://your-dashboard-supabase-url.supabase.co"
SUPABASE_SERVICE_KEY="your-supabase-service-role-key"
LOCAL_DB_NAME="dashboard_aplo"
LOCAL_DB_USER="dashboard_user"
LOCAL_DB_PASSWORD="your_secure_password"
EXPORT_DIR="./database/exports"
DATE=$(date +"%Y%m%d_%H%M%S")

# CrÃ©er rÃ©pertoire d'export
mkdir -p $EXPORT_DIR

echo "ğŸ“¦ Installation des outils d'export..."

# Installer pg_dump si pas prÃ©sent
if ! command -v pg_dump &> /dev/null; then
    echo "âŒ pg_dump non trouvÃ©. Installation de postgresql-client..."
    sudo apt-get update
    sudo apt-get install -y postgresql-client
fi

# Installer Node.js si pas prÃ©sent
if ! command -v node &> /dev/null; then
    echo "âŒ Node.js non trouvÃ©. Installation..."
    curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
    sudo apt-get install -y nodejs
fi

echo "ğŸ”§ CrÃ©ation du script d'export..."

# CrÃ©er le script Node.js pour l'export
cat > export-supabase.js << 'EOF'
const { createClient } = require('@supabase/supabase-js');
const fs = require('fs');
const path = require('path');

// Configuration
const supabaseUrl = process.env.SUPABASE_URL;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_KEY;
const exportDir = process.env.EXPORT_DIR || './exports';

if (!supabaseUrl || !supabaseServiceKey) {
    console.error('âŒ Variables d\'environnement manquantes');
    console.error('SUPABASE_URL et SUPABASE_SERVICE_KEY requis');
    process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseServiceKey);

// Tables Ã  exporter
const tables = [
    'users',
    'user_profiles',
    'communes',
    'categories',
    'events',
    'subscriptions',
    'payments',
    'onboarding_progress',
    'admin_notifications',
    'team_invitations'
];

async function exportTable(tableName) {
    console.log(`ğŸ“‹ Export de la table: ${tableName}`);
    
    try {
        const { data, error } = await supabase
            .from(tableName)
            .select('*');
        
        if (error) {
            console.error(`âŒ Erreur export ${tableName}:`, error);
            return null;
        }
        
        const filename = path.join(exportDir, `${tableName}_${Date.now()}.json`);
        fs.writeFileSync(filename, JSON.stringify(data, null, 2));
        
        console.log(`âœ… ${tableName}: ${data.length} enregistrements exportÃ©s vers ${filename}`);
        return { tableName, data, filename };
        
    } catch (error) {
        console.error(`âŒ Erreur export ${tableName}:`, error);
        return null;
    }
}

async function exportAllTables() {
    console.log('ğŸš€ DÃ©but de l\'export de toutes les tables...');
    
    const results = [];
    
    for (const table of tables) {
        const result = await exportTable(table);
        if (result) {
            results.push(result);
        }
    }
    
    // CrÃ©er un fichier de rÃ©sumÃ©
    const summary = {
        exportDate: new Date().toISOString(),
        tables: results.map(r => ({
            name: r.tableName,
            recordCount: r.data.length,
            filename: path.basename(r.filename)
        }))
    };
    
    const summaryFile = path.join(exportDir, `export_summary_${Date.now()}.json`);
    fs.writeFileSync(summaryFile, JSON.stringify(summary, null, 2));
    
    console.log('âœ… Export terminÃ© !');
    console.log(`ğŸ“Š RÃ©sumÃ© sauvegardÃ© dans: ${summaryFile}`);
    
    return results;
}

// ExÃ©cuter l'export
exportAllTables().catch(console.error);
EOF

echo "ğŸ“¦ Installation des dÃ©pendances..."
npm install @supabase/supabase-js

echo "ğŸš€ DÃ©but de l'export..."

# Exporter les variables d'environnement
export SUPABASE_URL=$SUPABASE_URL
export SUPABASE_SERVICE_KEY=$SUPABASE_SERVICE_KEY
export EXPORT_DIR=$EXPORT_DIR

# ExÃ©cuter l'export
node export-supabase.js

echo ""
echo "ğŸ—„ï¸ CrÃ©ation du script d'import PostgreSQL..."

# CrÃ©er le script d'import PostgreSQL
cat > import-to-postgresql.sql << 'EOF'
-- Script d'import PostgreSQL pour OT Dashboard APLO
-- Usage: psql -U dashboard_user -d dashboard_aplo -f import-to-postgresql.sql

-- Activer les extensions nÃ©cessaires
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "postgis";

-- Nettoyer les tables existantes (ATTENTION: supprime toutes les donnÃ©es)
TRUNCATE TABLE events CASCADE;
TRUNCATE TABLE user_profiles CASCADE;
TRUNCATE TABLE subscriptions CASCADE;
TRUNCATE TABLE payments CASCADE;
TRUNCATE TABLE onboarding_progress CASCADE;
TRUNCATE TABLE admin_notifications CASCADE;
TRUNCATE TABLE team_invitations CASCADE;

-- RÃ©initialiser les sÃ©quences
ALTER SEQUENCE events_id_seq RESTART WITH 1;
ALTER SEQUENCE user_profiles_id_seq RESTART WITH 1;
ALTER SEQUENCE subscriptions_id_seq RESTART WITH 1;
ALTER SEQUENCE payments_id_seq RESTART WITH 1;
ALTER SEQUENCE onboarding_progress_id_seq RESTART WITH 1;
ALTER SEQUENCE admin_notifications_id_seq RESTART WITH 1;
ALTER SEQUENCE team_invitations_id_seq RESTART WITH 1;

-- Note: Les donnÃ©es seront importÃ©es via les fichiers JSON exportÃ©s
-- Utiliser le script Node.js d'import pour traiter les fichiers JSON
EOF

# CrÃ©er le script Node.js d'import
cat > import-to-postgresql.js << 'EOF'
const { Client } = require('pg');
const fs = require('fs');
const path = require('path');

// Configuration PostgreSQL local
const client = new Client({
    host: 'localhost',
    port: 5432,
    database: process.env.LOCAL_DB_NAME || 'dashboard_aplo',
    user: process.env.LOCAL_DB_USER || 'dashboard_user',
    password: process.env.LOCAL_DB_PASSWORD || 'your_secure_password'
});

const importDir = process.env.IMPORT_DIR || './exports';

async function importTable(tableName, data) {
    console.log(`ğŸ“¥ Import de la table: ${tableName} (${data.length} enregistrements)`);
    
    if (data.length === 0) {
        console.log(`âš ï¸ Table ${tableName} vide, ignorÃ©e`);
        return;
    }
    
    try {
        // GÃ©nÃ©rer les colonnes dynamiquement
        const columns = Object.keys(data[0]);
        const placeholders = columns.map((_, index) => `$${index + 1}`).join(', ');
        const columnNames = columns.join(', ');
        
        const query = `
            INSERT INTO ${tableName} (${columnNames})
            VALUES (${placeholders})
            ON CONFLICT (id) DO UPDATE SET
            ${columns.map(col => `${col} = EXCLUDED.${col}`).join(', ')}
        `;
        
        // InsÃ©rer les donnÃ©es par batch
        const batchSize = 100;
        for (let i = 0; i < data.length; i += batchSize) {
            const batch = data.slice(i, i + batchSize);
            
            for (const row of batch) {
                const values = columns.map(col => row[col]);
                await client.query(query, values);
            }
            
            console.log(`  âœ… Batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(data.length / batchSize)}`);
        }
        
        console.log(`âœ… Table ${tableName} importÃ©e avec succÃ¨s`);
        
    } catch (error) {
        console.error(`âŒ Erreur import ${tableName}:`, error);
        throw error;
    }
}

async function importAllTables() {
    console.log('ğŸš€ DÃ©but de l\'import vers PostgreSQL...');
    
    try {
        await client.connect();
        console.log('âœ… Connexion PostgreSQL Ã©tablie');
        
        // Lire le rÃ©pertoire d'export
        const files = fs.readdirSync(importDir)
            .filter(file => file.endsWith('.json') && !file.includes('summary'));
        
        for (const file of files) {
            const tableName = file.split('_')[0];
            const filePath = path.join(importDir, file);
            
            console.log(`ğŸ“‹ Traitement du fichier: ${file}`);
            
            const data = JSON.parse(fs.readFileSync(filePath, 'utf8'));
            await importTable(tableName, data);
        }
        
        console.log('ğŸ‰ Import terminÃ© avec succÃ¨s !');
        
    } catch (error) {
        console.error('âŒ Erreur lors de l\'import:', error);
        throw error;
    } finally {
        await client.end();
    }
}

// ExÃ©cuter l'import
importAllTables().catch(console.error);
EOF

echo "ğŸ“¦ Installation des dÃ©pendances PostgreSQL..."
npm install pg

echo ""
echo "ğŸ‰ Scripts d'export/import crÃ©Ã©s !"
echo "================================"
echo ""
echo "ğŸ“‹ Prochaines Ã©tapes :"
echo ""
echo "1. ğŸ”§ Configurer les variables dans le script :"
echo "   - SUPABASE_URL"
echo "   - SUPABASE_SERVICE_KEY"
echo "   - LOCAL_DB_PASSWORD"
echo ""
echo "2. ğŸ“¤ Exporter depuis Supabase :"
echo "   ./export-supabase-to-postgresql.sh"
echo ""
echo "3. ğŸ“¥ Importer vers PostgreSQL local :"
echo "   export LOCAL_DB_PASSWORD='your_password'"
echo "   node import-to-postgresql.js"
echo ""
echo "4. ğŸ” VÃ©rifier l'import :"
echo "   psql -U dashboard_user -d dashboard_aplo -c 'SELECT COUNT(*) FROM events;'"
echo ""
echo "ğŸ“ Fichiers crÃ©Ã©s :"
echo "   - export-supabase.js"
echo "   - import-to-postgresql.js"
echo "   - import-to-postgresql.sql"
echo "   - exports/ (rÃ©pertoire)"
echo "" 